{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7a1da0-9709-435b-9068-fe5cb0dbe85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the necessary library\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "import s3fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aadf6a83-dee3-4b5d-af0a-583c2569a756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialising new sagemaker session as \"sess\".\n",
    "sess = sagemaker.Session()\n",
    "# Bucket variable is used for storing the location of the bucket\n",
    "bucket = 'sagemaker-studio-009676737623-l4vs7j0o0ib'\n",
    "# Assigning the prefix variable \n",
    "prefix = 'mlops-level1-data' \n",
    "# Check for necessary permission needed for training and deploying models. \n",
    "role = sagemaker.get_execution_role()\n",
    "# To understand where this session is configured to operate.\n",
    "region = boto3.Session().region_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243a0b6d-d2da-44ff-aeee-e37b3520b786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'HumanActivity-InferenceEndpoint-final-2023-09-24-0840'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040dadf-1cfd-4ca7-b04f-926471dfc1c4",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8566f7-4837-4a5d-b92f-881f52706c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture path: s3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/datacapture\n",
      "Report path: s3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/reports\n"
     ]
    }
   ],
   "source": [
    "data_capture_prefix = \"{}/datacapture\".format(prefix)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(bucket, data_capture_prefix)\n",
    "reports_prefix = \"{}/reports\".format(prefix)\n",
    "s3_report_path = \"s3://{}/{}\".format(bucket, reports_prefix)\n",
    "\n",
    "print(\"Capture path: {}\".format(s3_capture_upload_path))\n",
    "print(\"Report path: {}\".format(s3_report_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9153da14-7ae1-4041-b717-ead77c4d8f64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-21 17:27:17        103 mlops-level1-data/datacapture/input/2023/09/21/17/4cd90f84-650d-4233-99c5-83ffb84d8364.json\n",
      "2023-09-23 07:28:39        119 mlops-level1-data/datacapture/input/2023/09/23/07/1431e7d4-96b3-4767-a45d-5c6204bf5280.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {s3_capture_upload_path}/input/ --recursive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e28c1acd-0803-4983-aac9-682dbd24fe4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "captured_input_s3_key = [\n",
    "    k[\"Key\"]\n",
    "    for k in s3.list_objects_v2(Bucket=bucket, Prefix=f\"{data_capture_prefix}/input/\")[\"Contents\"]\n",
    "]\n",
    "assert len(captured_input_s3_key) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78bed6a9-591f-4002-9c6c-6b7117b476bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "sample_input_body = s3.get_object(Bucket=bucket, Key=captured_input_s3_key[0])[\"Body\"]\n",
    "sample_input_content = json.loads(sample_input_body.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2227d4f6-021e-4ddb-8d7b-29963fe74a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prefix': 's3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/baseline/data/v1.csv'},\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b7c239-71f2-4a84-a212-3cf7aeaa06f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-21 17:27:17        114 mlops-level1-data/datacapture/output/2023/09/21/17/b66aed65-49f5-4a4d-a6ee-243ccc0860a9.json\n",
      "2023-09-23 07:28:39        119 mlops-level1-data/datacapture/output/2023/09/23/07/571f3b71-0d2a-46d5-922f-8fdfa070f008.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {s3_capture_upload_path}/output/ --recursive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8561afb-6168-4f27-851f-5d0a62d5d7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "captured_input_s3_key = [\n",
    "    k[\"Key\"]\n",
    "    for k in s3.list_objects_v2(Bucket=bucket, Prefix=f\"{data_capture_prefix}/output/\")[\"Contents\"]\n",
    "]\n",
    "assert len(captured_input_s3_key) > 0\n",
    "sample_output_body = s3.get_object(Bucket=bucket, Key=captured_input_s3_key[0])[\"Body\"]\n",
    "sample_output_content = json.loads(sample_output_body.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0046fdfa-49ca-4316-9dc9-b4d5b8132c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prefix': 's3://sagemaker-ap-south-1-009676737623/sagemaker-scikit-learn-2023-09-21-17-23-05-878/'},\n",
       " 'v1.csv.out']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9ec269ee-389b-4aa1-9d66-d382a9e8de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( baseline_data_uri + \"/training-inputs-with-header.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de78d8-5a28-4d1c-9739-a9ef8bbca682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "910a9101-3ddc-4ef5-bf4c-4b167661d0b0",
   "metadata": {},
   "source": [
    "## Model Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05ba132d-ab31-417c-b45a-5b405094f073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import BatchDataCaptureConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d13437-7b5e-4500-bf62-7c3a3d80fce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/baseline/data\n",
      "Baseline results uri: s3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/baseline/results\n"
     ]
    }
   ],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "baseline_prefix = prefix + \"/baseline\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f06e0f-1c3a-4c86-9a24-d3ac4238ca5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_path = baseline_data_uri + \"/training-inputs-with-header.csv\"\n",
    "#feature_v1_data.to_csv(training_data_path,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33f07a2a-8a5c-499f-a647-5090984a8bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2023-09-24-09-53-53-668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................\u001b[34m2023-09-24 09:57:45.324399: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:45.324432: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:46.835755: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:46.835783: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:46.835802: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-93-246.ap-south-1.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:46.836069: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,408 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:ap-south-1:009676737623:processing-job/baseline-suggestion-job-2023-09-24-09-53-53-668', 'ProcessingJobName': 'baseline-suggestion-job-2023-09-24-09-53-53-668', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '126357580389.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/baseline/data/training-inputs-with-header.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/baseline/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::009676737623:role/sagemaker-full-permission', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,408 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,408 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,408 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,408 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,408 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,465 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,466 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,466 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,474 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,474 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,474 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,952 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.93.246\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-\u001b[0m\n",
      "\u001b[34myarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_382\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,959 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:48,962 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-714ea3e4-2ef5-45a9-b77c-6746da9a3b01\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,438 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,448 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,450 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,451 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,456 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,456 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,456 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,456 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,486 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,497 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,497 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,500 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,504 INFO blockmanagement.BlockManager: The block deletion will start around 2023 Sep 24 09:57:49\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,505 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,505 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,506 INFO util.GSet: 2.0% max memory 3.1 GB = 63.6 MB\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,506 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,580 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,583 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,583 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,583 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,583 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,583 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,583 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,584 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,584 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,584 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,584 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,584 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,609 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,609 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,609 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,609 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,611 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,611 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,611 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,611 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,615 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,619 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,619 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,619 INFO util.GSet: 0.25% max memory 3.1 GB = 8.0 MB\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,619 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,625 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,625 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,625 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,629 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,629 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,631 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,631 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,631 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 977.7 KB\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,631 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,654 INFO namenode.FSImage: Allocated new BlockPoolId: BP-461554901-10.0.93.246-1695549469646\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,665 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,672 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,747 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,759 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,762 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.93.246\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:49,771 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:51,827 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:51,827 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:53,906 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:53,907 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:56,016 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:56,016 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:58,112 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:57:58,113 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:00,416 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:00,417 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:10,426 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:12,224 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:12,623 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:12,665 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:12,685 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,212 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,235 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,235 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,236 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,236 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,259 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11536, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,273 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,275 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,325 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,325 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,325 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,326 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,326 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,643 INFO util.Utils: Successfully started service 'sparkDriver' on port 36369.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,671 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,707 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,726 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,727 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,759 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,782 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-3ba80efe-db56-4e3c-979b-27bd76843358\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,799 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,835 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:13,870 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.93.246:36369/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1695549493207\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:14,346 INFO client.RMProxy: Connecting to ResourceManager at /10.0.93.246:8032\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,131 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,131 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,138 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15731 MB per container)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,139 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,139 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,139 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,145 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:15,228 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:16,996 INFO yarn.Client: Uploading resource file:/tmp/spark-6a8077c9-87b8-451d-810b-e6354c9e64aa/__spark_libs__4751998880864772680.zip -> hdfs://10.0.93.246/user/root/.sparkStaging/application_1695549475614_0001/__spark_libs__4751998880864772680.zip\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:18,620 INFO yarn.Client: Uploading resource file:/tmp/spark-6a8077c9-87b8-451d-810b-e6354c9e64aa/__spark_conf__1845496984934751660.zip -> hdfs://10.0.93.246/user/root/.sparkStaging/application_1695549475614_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,063 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,063 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,063 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,063 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,063 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,091 INFO yarn.Client: Submitting application application_1695549475614_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:19,284 INFO impl.YarnClientImpl: Submitted application application_1695549475614_0001\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:20,289 INFO yarn.Client: Application report for application_1695549475614_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:20,294 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Sun Sep 24 09:58:19 +0000 2023] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1695549499186\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1695549475614_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:21,297 INFO yarn.Client: Application report for application_1695549475614_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:22,300 INFO yarn.Client: Application report for application_1695549475614_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:23,303 INFO yarn.Client: Application report for application_1695549475614_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:24,311 INFO yarn.Client: Application report for application_1695549475614_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:24,671 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1695549475614_0001), /proxy/application_1695549475614_0001\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,317 INFO yarn.Client: Application report for application_1695549475614_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,319 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.93.246\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1695549499186\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1695549475614_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,321 INFO cluster.YarnClientSchedulerBackend: Application application_1695549475614_0001 has started running.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,344 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37939.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,344 INFO netty.NettyBlockTransferService: Server created on 10.0.93.246:37939\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,346 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,356 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.93.246, 37939, None)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,360 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.93.246:37939 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.93.246, 37939, None)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,363 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.93.246, 37939, None)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,365 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.93.246, 37939, None)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:25,493 INFO util.log: Logging initialized @14848ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:26,150 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:30,528 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.93.246:40014) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:30,720 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:36925 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 36925, None)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:44,269 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:44,383 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:44,416 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:44,419 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,264 INFO datasources.InMemoryFileIndex: It took 27 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,403 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,651 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,654 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.93.246:37939 (size: 39.3 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,659 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,964 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,966 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:45,969 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 2441537\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,016 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,035 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,036 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,036 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,038 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,044 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,071 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,075 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,075 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.93.246:37939 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,076 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,092 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,093 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,133 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4640 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:46,396 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:36925 (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,359 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:36925 (size: 39.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,788 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1667 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,790 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,797 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.731 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,801 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,801 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,803 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.786271 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,951 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.93.246:37939 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:47,960 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:36925 in memory (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:49,928 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:49,930 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:49,933 INFO datasources.FileSourceStrategy: Output Data Schema: struct<tGravityAcc-energy()-X: string, tGravityAcc-min()-X: string, tGravityAcc-max()-X: string, tGravityAcc-max()-Y: string, tGravityAcc-min()-Y: string ... 11 more fields>\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,137 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,154 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,156 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.93.246:37939 (size: 39.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,157 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,171 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,215 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,217 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,217 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,217 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,219 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,227 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,315 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 17.6 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,321 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,322 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.93.246:37939 (size: 8.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,323 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,324 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,324 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,330 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4968 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:50,384 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:36925 (size: 8.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,206 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:36925 (size: 39.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,550 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:36925 (size: 2.6 MiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,683 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1357 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,683 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,685 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 1.453 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,685 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,685 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,685 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 1.469714 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,957 INFO codegen.CodeGenerator: Code generated in 205.411688 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,995 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.93.246:37939 in memory (size: 8.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:51,996 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:36925 in memory (size: 8.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,491 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,629 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,632 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,632 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,633 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,635 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,638 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,661 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 114.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,664 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,664 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.93.246:37939 (size: 34.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,665 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,667 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,667 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,677 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:52,704 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:36925 (size: 34.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,166 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1491 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,166 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,168 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.527 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,169 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,169 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,170 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,170 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,244 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,246 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,246 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,246 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,247 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,249 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,266 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 167.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,268 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 46.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,269 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.93.246:37939 (size: 46.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,270 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,271 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,271 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,274 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,295 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:36925 (size: 46.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,339 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,656 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 383 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,658 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.402 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,659 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,659 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,659 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,660 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.415757 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,694 INFO codegen.CodeGenerator: Code generated in 24.571384 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:54,971 INFO codegen.CodeGenerator: Code generated in 33.665752 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,033 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,035 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,035 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,035 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,036 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,037 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,054 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 38.4 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,056 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,057 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.93.246:37939 (size: 16.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,057 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,058 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,058 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,060 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4968 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,074 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:36925 (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,757 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 698 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,758 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.719 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,758 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,758 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,758 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:55,759 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.725225 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,276 INFO codegen.CodeGenerator: Code generated in 105.799492 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,284 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,284 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,284 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,284 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,285 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,286 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,291 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 73.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,293 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,294 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.93.246:37939 (size: 23.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,294 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,295 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,295 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,296 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,310 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:36925 (size: 23.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,547 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 250 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,547 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,548 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.261 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,548 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,548 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,548 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,548 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,754 INFO codegen.CodeGenerator: Code generated in 92.610807 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,768 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,769 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,769 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,769 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,770 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,771 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,775 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.2 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,776 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,777 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.93.246:37939 (size: 19.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,778 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,778 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,779 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,781 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,792 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:36925 (size: 19.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,798 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,907 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 126 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,907 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,909 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.136 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,910 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,910 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,910 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.142594 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,973 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:36925 in memory (size: 23.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,987 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.93.246:37939 in memory (size: 23.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,993 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:36925 in memory (size: 46.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:56,995 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.93.246:37939 in memory (size: 46.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,017 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:36925 in memory (size: 34.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,018 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.93.246:37939 in memory (size: 34.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,055 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.93.246:37939 in memory (size: 16.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,057 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:36925 in memory (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,065 INFO codegen.CodeGenerator: Code generated in 72.812891 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,079 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.93.246:37939 in memory (size: 19.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,084 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:36925 in memory (size: 19.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,331 INFO scheduler.DAGScheduler: Registering RDD 42 (collect at AnalysisRunner.scala:326) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,331 INFO scheduler.DAGScheduler: Got map stage job 7 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,331 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 9 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,331 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,332 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,334 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,341 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 83.5 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,343 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,344 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.93.246:37939 (size: 27.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,345 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,345 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,346 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,347 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,367 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:36925 (size: 27.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,626 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 279 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,626 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,627 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (collect at AnalysisRunner.scala:326) finished in 0.292 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,628 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,628 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,628 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,628 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,668 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,670 INFO scheduler.DAGScheduler: Got job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,670 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,670 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,671 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,671 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[45] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,681 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 168.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,683 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 46.3 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,684 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.93.246:37939 (size: 46.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,685 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,685 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[45] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,685 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,687 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,697 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:36925 (size: 46.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,717 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,843 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 156 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,843 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,844 INFO scheduler.DAGScheduler: ResultStage 11 (collect at AnalysisRunner.scala:326) finished in 0.170 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,845 INFO scheduler.DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,846 INFO cluster.YarnScheduler: Killing all running tasks in stage 11: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:57,848 INFO scheduler.DAGScheduler: Job 8 finished: collect at AnalysisRunner.scala:326, took 0.179424 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,038 INFO codegen.CodeGenerator: Code generated in 18.816862 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,068 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,069 INFO scheduler.DAGScheduler: Got job 9 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,070 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,070 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,071 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,080 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,087 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 38.3 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,089 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,090 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.93.246:37939 (size: 16.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,091 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,092 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,092 INFO cluster.YarnScheduler: Adding task set 12.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,094 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4968 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,109 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:36925 (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,438 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 344 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,438 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,439 INFO scheduler.DAGScheduler: ResultStage 12 (treeReduce at KLLRunner.scala:107) finished in 0.358 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,439 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,440 INFO cluster.YarnScheduler: Killing all running tasks in stage 12: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,440 INFO scheduler.DAGScheduler: Job 9 finished: treeReduce at KLLRunner.scala:107, took 0.371978 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,705 INFO codegen.CodeGenerator: Code generated in 66.725319 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,713 INFO scheduler.DAGScheduler: Registering RDD 60 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,713 INFO scheduler.DAGScheduler: Got map stage job 10 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,713 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,713 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,713 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,714 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[60] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,718 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 73.8 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,720 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,721 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.93.246:37939 (size: 23.6 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,722 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,722 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[60] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,723 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,725 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,736 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:36925 (size: 23.6 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,932 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 208 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,933 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,934 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (collect at AnalysisRunner.scala:326) finished in 0.217 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,935 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,935 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,935 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:58,935 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,025 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,027 INFO scheduler.DAGScheduler: Got job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,029 INFO scheduler.DAGScheduler: Final stage: ResultStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,029 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,029 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,031 INFO scheduler.DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,034 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 66.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,036 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,038 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.93.246:37939 (size: 19.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,039 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,040 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,043 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,045 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 11) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,058 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:36925 (size: 19.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,063 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,070 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 11) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,070 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,071 INFO scheduler.DAGScheduler: ResultStage 15 (collect at AnalysisRunner.scala:326) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,071 INFO scheduler.DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,071 INFO cluster.YarnScheduler: Killing all running tasks in stage 15: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,072 INFO scheduler.DAGScheduler: Job 11 finished: collect at AnalysisRunner.scala:326, took 0.046045 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,249 INFO scheduler.DAGScheduler: Registering RDD 68 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,250 INFO scheduler.DAGScheduler: Got map stage job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,250 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 16 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,251 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,253 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,254 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[68] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,259 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 63.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,262 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,263 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.93.246:37939 (size: 22.6 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,264 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,264 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[68] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,265 INFO cluster.YarnScheduler: Adding task set 16.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,266 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,280 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:36925 (size: 22.6 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,638 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 12) in 372 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,638 INFO cluster.YarnScheduler: Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,639 INFO scheduler.DAGScheduler: ShuffleMapStage 16 (collect at AnalysisRunner.scala:326) finished in 0.383 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,639 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,639 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,639 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,639 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,671 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,672 INFO scheduler.DAGScheduler: Got job 13 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,673 INFO scheduler.DAGScheduler: Final stage: ResultStage 18 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,673 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,673 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,673 INFO scheduler.DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[71] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,678 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 115.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,680 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,681 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.93.246:37939 (size: 35.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,681 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,682 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[71] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,682 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,683 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,697 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:36925 (size: 35.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,708 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,819 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 13) in 136 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,819 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,820 INFO scheduler.DAGScheduler: ResultStage 18 (collect at AnalysisRunner.scala:326) finished in 0.146 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,822 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,823 INFO cluster.YarnScheduler: Killing all running tasks in stage 18: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,823 INFO scheduler.DAGScheduler: Job 13 finished: collect at AnalysisRunner.scala:326, took 0.151889 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,838 INFO codegen.CodeGenerator: Code generated in 11.641114 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,928 INFO codegen.CodeGenerator: Code generated in 23.621074 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,965 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,966 INFO scheduler.DAGScheduler: Got job 14 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,967 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,967 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,968 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,968 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[81] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,977 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 36.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,979 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,980 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.93.246:37939 (size: 16.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,985 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,986 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[81] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,986 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:58:59,988 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4968 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:00,006 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:36925 (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:01,671 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 14) in 1683 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:01,671 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:01,673 INFO scheduler.DAGScheduler: ResultStage 19 (treeReduce at KLLRunner.scala:107) finished in 1.701 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:01,676 INFO scheduler.DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:01,676 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:01,677 INFO scheduler.DAGScheduler: Job 14 finished: treeReduce at KLLRunner.scala:107, took 1.711378 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,203 INFO codegen.CodeGenerator: Code generated in 120.671443 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,227 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,228 INFO scheduler.DAGScheduler: Got map stage job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,228 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,229 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,230 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,231 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,245 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 42.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,250 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,252 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.93.246:37939 (size: 16.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,253 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,256 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,256 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,259 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 15) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,281 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:36925 (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,437 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 15) in 179 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,437 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,439 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.205 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,441 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,441 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,442 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,442 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,683 INFO codegen.CodeGenerator: Code generated in 130.127459 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,780 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,782 INFO scheduler.DAGScheduler: Got job 16 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,782 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,782 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,782 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,783 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,787 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 32.6 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,791 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,791 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.93.246:37939 (size: 11.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,792 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,793 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,793 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.93.246:37939 in memory (size: 16.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,794 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,795 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:36925 in memory (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,796 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 16) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,823 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:36925 (size: 11.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,830 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,909 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:36925 in memory (size: 27.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,911 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.93.246:37939 in memory (size: 27.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,933 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 16) in 136 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,933 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,934 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.150 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,935 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,935 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:02,935 INFO scheduler.DAGScheduler: Job 16 finished: collect at AnalysisRunner.scala:326, took 0.155232 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,010 INFO codegen.CodeGenerator: Code generated in 61.942187 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,020 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.93.246:37939 in memory (size: 19.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,025 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:36925 in memory (size: 19.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,059 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.93.246:37939 in memory (size: 16.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,067 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:36925 in memory (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,118 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:36925 in memory (size: 35.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,135 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.93.246:37939 in memory (size: 35.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,169 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,176 INFO scheduler.DAGScheduler: Registering RDD 97 (countByKey at ColumnProfiler.scala:592) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,177 INFO scheduler.DAGScheduler: Got job 17 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,178 INFO scheduler.DAGScheduler: Final stage: ResultStage 24 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,178 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,178 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,181 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[97] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,187 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.93.246:37939 in memory (size: 22.6 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,197 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:36925 in memory (size: 22.6 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,220 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 30.6 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,222 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,223 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.93.246:37939 (size: 14.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,224 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,224 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[97] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,224 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,226 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 17) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,239 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:36925 (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,254 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.93.246:37939 in memory (size: 46.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,258 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:36925 in memory (size: 46.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,277 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:36925 in memory (size: 23.6 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,292 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.93.246:37939 in memory (size: 23.6 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,320 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.93.246:37939 in memory (size: 16.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,330 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:36925 in memory (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,455 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 17) in 229 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,455 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,456 INFO scheduler.DAGScheduler: ShuffleMapStage 23 (countByKey at ColumnProfiler.scala:592) finished in 0.268 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,457 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,457 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,457 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 24)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,458 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,459 INFO scheduler.DAGScheduler: Submitting ResultStage 24 (ShuffledRDD[98] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,462 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,464 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,465 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.93.246:37939 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,466 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,467 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (ShuffledRDD[98] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,467 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,470 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 18) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,492 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:36925 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,498 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,534 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 18) in 65 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,535 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,536 INFO scheduler.DAGScheduler: ResultStage 24 (countByKey at ColumnProfiler.scala:592) finished in 0.075 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,536 INFO scheduler.DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,537 INFO cluster.YarnScheduler: Killing all running tasks in stage 24: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,537 INFO scheduler.DAGScheduler: Job 17 finished: countByKey at ColumnProfiler.scala:592, took 0.367819 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,792 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,853 INFO codegen.CodeGenerator: Code generated in 12.36324 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,861 INFO scheduler.DAGScheduler: Registering RDD 103 (count at StatsGenerator.scala:66) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,862 INFO scheduler.DAGScheduler: Got map stage job 18 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,862 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 25 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,862 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,862 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,863 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[103] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,870 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 22.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,872 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,873 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.93.246:37939 (size: 10.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,874 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,876 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[103] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,877 INFO cluster.YarnScheduler: Adding task set 25.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,879 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4957 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,897 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:36925 (size: 10.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,968 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 19) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,968 INFO cluster.YarnScheduler: Removed TaskSet 25.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,970 INFO scheduler.DAGScheduler: ShuffleMapStage 25 (count at StatsGenerator.scala:66) finished in 0.103 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,970 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,970 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,971 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,971 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:03,994 INFO codegen.CodeGenerator: Code generated in 9.622896 ms\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,007 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,009 INFO scheduler.DAGScheduler: Got job 19 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,010 INFO scheduler.DAGScheduler: Final stage: ResultStage 27 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,010 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,010 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,011 INFO scheduler.DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[106] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,014 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 11.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,016 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,017 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.93.246:37939 (size: 5.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,017 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,018 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[106] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,018 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,021 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,038 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:36925 (size: 5.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,043 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.93.246:40014\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,061 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 20) in 41 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,061 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,062 INFO scheduler.DAGScheduler: ResultStage 27 (count at StatsGenerator.scala:66) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,063 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,063 INFO cluster.YarnScheduler: Killing all running tasks in stage 27: Stage finished\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,064 INFO scheduler.DAGScheduler: Job 19 finished: count at StatsGenerator.scala:66, took 0.056104 s\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,557 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,579 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,649 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,650 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,659 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,693 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,763 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,764 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,770 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,777 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,822 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,822 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,822 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,859 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,861 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6a8077c9-87b8-451d-810b-e6354c9e64aa\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,872 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3919aa05-8c2f-4645-8771-08cc399411de\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,930 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2023-09-24 09:59:04,930 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f5f8b9a5ff0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=training_data_path,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d984efb-a258-4e67-8df1-fe9d3e1c1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Files:\n",
      "mlops-level1-data/baseline/results/constraints.json\n",
      " mlops-level1-data/baseline/results/statistics.json\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=baseline_results_prefix)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86656c5f-247e-4a6b-92c3-c7657e4ab6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a146d56-16d7-4304-9a18-caddbe363ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monitor Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e837d8cd-017a-4114-b753-0e0b136b91ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: model-monitor-schedule-realtime2023-09-24-10-30-51\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "from time import gmtime, strftime\n",
    "\n",
    "mon_schedule_name = \"model-monitor-schedule-realtime\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=EndpointInput(\n",
    "        endpoint_name=endpoint_name,\n",
    "        destination=\"/opt/ml/processing/input/endpoint\"\n",
    "    ),\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=statistics_path,\n",
    "    constraints=constraints_path,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aa77075-606f-4020-959e-69eecbd30b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sagemaker.model_monitor import CronExpressionGenerator\\nfrom sagemaker.model_monitor import BatchTransformInput\\nfrom sagemaker.model_monitor import MonitoringDatasetFormat\\nfrom time import gmtime, strftime\\n\\nstatistics_path = \"{}/statistics.json\".format(baseline_results_uri)\\nconstraints_path = \"{}/constraints.json\".format(baseline_results_uri)\\n\\nmon_schedule_name = \"DEMO-mlops1-model-monitor-schedule-\" + strftime(\\n    \"%Y-%m-%d-%H-%M-%S\", gmtime()\\n)\\nmy_default_monitor.create_monitoring_schedule(\\n    monitor_schedule_name=mon_schedule_name,\\n    batch_transform_input=BatchTransformInput(\\n        data_captured_destination_s3_uri=s3_capture_upload_path,\\n        destination=\"/opt/ml/processing/input\",\\n        dataset_format=MonitoringDatasetFormat.csv(header=False),\\n    ),\\n    output_s3_uri=s3_report_path,\\n    statistics=statistics_path,\\n    constraints=constraints_path,\\n    schedule_cron_expression=CronExpressionGenerator.hourly(),\\n    enable_cloudwatch_metrics=True,\\n)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.model_monitor import BatchTransformInput\n",
    "from sagemaker.model_monitor import MonitoringDatasetFormat\n",
    "from time import gmtime, strftime\n",
    "\n",
    "statistics_path = \"{}/statistics.json\".format(baseline_results_uri)\n",
    "constraints_path = \"{}/constraints.json\".format(baseline_results_uri)\n",
    "\n",
    "mon_schedule_name = \"DEMO-mlops1-model-monitor-schedule-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime()\n",
    ")\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    batch_transform_input=BatchTransformInput(\n",
    "        data_captured_destination_s3_uri=s3_capture_upload_path,\n",
    "        destination=\"/opt/ml/processing/input\",\n",
    "        dataset_format=MonitoringDatasetFormat.csv(header=False),\n",
    "    ),\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=statistics_path,\n",
    "    constraints=constraints_path,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1890aa0-453d-4ef0-b9df-ee4fffb66482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Scheduled\n"
     ]
    }
   ],
   "source": [
    "desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "print(\"Schedule status: {}\".format(desc_schedule_result[\"MonitoringScheduleStatus\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "130d9998-a500-4bf1-8aa8-e2dcffaf8ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\n",
      "We will have to wait till we hit the hour...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mon_executions = my_default_monitor.list_executions()\n",
    "print(\n",
    "    \"We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\\nWe will have to wait till we hit the hour...\"\n",
    ")\n",
    "\n",
    "while len(mon_executions) == 0:\n",
    "    print(\"Waiting for the 1st execution to happen...\")\n",
    "    time.sleep(60)\n",
    "    mon_executions = my_default_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98225c45-667b-4fa0-be23-9cf0ca67a289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job model-monitoring-202309241100-3ebbbf6e34f2080a3c63bb75: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m latest_execution \u001b[38;5;241m=\u001b[39m mon_executions[\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m ]  \u001b[38;5;66;03m# latest execution's index is -1, second to last is -2 and so on..\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# time.sleep(60)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mlatest_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatest execution status: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(latest_execution\u001b[38;5;241m.\u001b[39mdescribe()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessingJobStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatest execution result: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(latest_execution\u001b[38;5;241m.\u001b[39mdescribe()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExitMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:1115\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mlogs_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:4289\u001b[0m, in \u001b[0;36mSession.wait_for_processing_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   4275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker Processing job to complete.\u001b[39;00m\n\u001b[1;32m   4276\u001b[0m \n\u001b[1;32m   4277\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4286\u001b[0m \u001b[38;5;124;03m    exceptions.UnexpectedStatusException: If the processing job fails.\u001b[39;00m\n\u001b[1;32m   4287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4288\u001b[0m desc \u001b[38;5;241m=\u001b[39m _wait_until(\u001b[38;5;28;01mlambda\u001b[39;00m: _processing_job_status(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client, job), poll)\n\u001b[0;32m-> 4289\u001b[0m \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6813\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   6808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   6809\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6810\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6811\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6812\u001b[0m     )\n\u001b[0;32m-> 6813\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6814\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6815\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6816\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6817\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job model-monitoring-202309241100-3ebbbf6e34f2080a3c63bb75: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[\n",
    "    -1\n",
    "]  # latest execution's index is -1, second to last is -2 and so on..\n",
    "# time.sleep(60)\n",
    "latest_execution.wait(logs=False)\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()[\"ProcessingJobStatus\"]))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()[\"ExitMessage\"]))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if latest_job[\"ProcessingJobStatus\"] != \"Completed\":\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf5cc922-c9bf-476a-9442-86286c30e35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Uri: s3://sagemaker-studio-009676737623-l4vs7j0o0ib/mlops-level1-data/reports/DEMO-xgb-churn-pred-model-monitor-schedule-2023-09-21-17-54-46/2023/09/21/18\n"
     ]
    }
   ],
   "source": [
    "report_uri = latest_execution.output.destination\n",
    "print(\"Report Uri: {}\".format(report_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbf69b91-1d22-4b5b-8a09-e1dc3a51ad65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report bucket: sagemaker-studio-009676737623-l4vs7j0o0ib\n",
      "Report key: mlops-level1-data/reports/DEMO-xgb-churn-pred-model-monitor-schedule-2023-09-21-17-54-46/2023/09/21/18\n",
      "Found Report Files:\n",
      "mlops-level1-data/reports/DEMO-xgb-churn-pred-model-monitor-schedule-2023-09-21-17-54-46/2023/09/21/18/constraint_violations.json\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "s3uri = urlparse(report_uri)\n",
    "report_bucket = s3uri.netloc\n",
    "report_key = s3uri.path.lstrip(\"/\")\n",
    "print(\"Report bucket: {}\".format(report_bucket))\n",
    "print(\"Report key: {}\".format(report_key))\n",
    "\n",
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=report_bucket, Prefix=report_key)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Report Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2909949c-67ae-48b3-a7d7-31587fa51500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing columns</td>\n",
       "      <td>missing_column_check</td>\n",
       "      <td>There are missing columns in current dataset. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_name constraint_check_type  \\\n",
       "0  Missing columns  missing_column_check   \n",
       "\n",
       "                                         description  \n",
       "0  There are missing columns in current dataset. ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations = my_default_monitor.latest_monitoring_constraint_violations()\n",
    "#pd.set_option(\"display.max_colwidth\", -1)\n",
    "constraints_df = json_normalize(violations.body_dict[\"violations\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50d83e-f1ec-4517-b166-84d4a64f80de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd093e-e9c8-4996-894d-d163ac7cc80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66dc0fa-78e2-413c-a858-4d837fd5c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
